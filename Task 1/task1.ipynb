{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"name":"task1.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"bb163b7b"},"source":["Step 1. Ensure that you have the dataset file named `transactions.csv` in the current directory.\n","\n","The dataset is a subset of https://www.kaggle.com/ealaxi/paysim1/version/2 which was originally generated as part of the following research:\n","\n","E. A. Lopez-Rojas , A. Elmir, and S. Axelsson. \"PaySim: A financial mobile money simulator for fraud detection\". In: The 28th European Modeling and Simulation Symposium-EMSS, Larnaca, Cyprus. 2016"],"id":"bb163b7b"},{"cell_type":"markdown","metadata":{"id":"72c898bd"},"source":["Step 2. Complete the following exercises.\n","\n","0. Read the dataset (`transactions.csv`) as a Pandas dataframe. Note that the first row of the CSV contains the column names.\n","\n","0. Return the column names as a list from the dataframe.\n","\n","0. Return the first k rows from the dataframe.\n","\n","0. Return a random sample of k rows from the dataframe.\n","\n","0. Return a list of the unique transaction types.\n","\n","0. Return a Pandas series of the top 10 transaction destinations with frequencies.\n","\n","0. Return all the rows from the dataframe for which fraud was detected.\n","\n","0. Bonus. Return a dataframe that contains the number of distinct destinations that each source has interacted with to, sorted in descending order. You will find [groupby](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) and [agg](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html) useful. The predefined aggregate functions are under `pandas.core.groupby.GroupBy.*`. See the [left hand column](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.nunique.html)."],"id":"72c898bd"},{"cell_type":"markdown","metadata":{"id":"2f146b9d"},"source":["Use the empty cell to test the exercises. If you modify the original `df`, you can rerun the cell containing `exercise_0`."],"id":"2f146b9d"},{"cell_type":"code","metadata":{"id":"EDd3m5pMN01e"},"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","def exercise_0(file):\n","    pass\n","\n","def exercise_1(df):\n","    pass\n","\n","def exercise_2(df, k):\n","    pass\n","\n","def exercise_3(df, k):\n","    pass\n","\n","def exercise_4(df):\n","    pass\n","\n","def exercise_5(df):\n","    pass\n","\n","def exercise_6(df):\n","    pass\n","\n","def exercise_7(df):\n","    pass\n","\n","def visual_1(df):\n","    pass\n","\n","def visual_2(df):\n","    pass\n","\n","def exercise_custom(df):\n","    pass\n","    \n","def visual_custom(df):\n","    pass"],"id":"EDd3m5pMN01e","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"346fc3fc"},"source":["df = exercise_0('transactions.csv')"],"id":"346fc3fc","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9158f0bd"},"source":["# Test exercises here\n"],"id":"9158f0bd","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ed2dc2f4"},"source":["Create graphs for the following. \n","1. Transaction types bar chart, Transaction types split by fraud bar chart\n","1. Origin account balance delta v. Destination account balance delta scatter plot for Cash Out transactions\n","\n","Ensure that the graphs have the following:\n"," - Title\n"," - Labeled Axes\n"," \n","The function plot the graph and then return a string containing a short description explaining the relevance of the chart."],"id":"ed2dc2f4"},{"cell_type":"code","metadata":{"id":"ab229b34"},"source":["def visual_1(df):\n","    def transaction_counts(df):\n","        # TODO\n","        pass\n","    def transaction_counts_split_by_fraud(df):\n","        # TODO\n","        pass\n","\n","    fig, axs = plt.subplots(2, figsize=(6,10))\n","    transaction_counts(df).plot(ax=axs[0], kind='bar')\n","    axs[0].set_title('TODO')\n","    axs[0].set_xlabel('TODO')\n","    axs[0].set_ylabel('TODO')\n","    transaction_counts_split_by_fraud(df).plot(ax=axs[1], kind='bar')\n","    axs[1].set_title('TODO')\n","    axs[1].set_xlabel('TODO')\n","    axs[1].set_ylabel('TODO')\n","    fig.suptitle('TODO')\n","    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n","    for ax in axs:\n","      for p in ax.patches:\n","          ax.annotate(p.get_height(), (p.get_x(), p.get_height()))\n","    return 'TODO'\n","\n","visual_1(df)\n"],"id":"ab229b34","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"38ab2f47"},"source":["def visual_2(df):\n","    def query(df):\n","        # TODO\n","        pass\n","    plot = query(df).plot.scatter(x='TODO',y='TODO')\n","    plot.set_title('TODO')\n","    plot.set_xlim(left=-1e3, right=1e3)\n","    plot.set_ylim(bottom=-1e3, top=1e3)\n","    return 'TODO'\n","\n","visual_2(df)\n"],"id":"38ab2f47","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f572d06d"},"source":["Use your newly-gained Pandas skills to find an insight from the dataset. You have full flexibility to go in whichever direction interests you. Please create a visual as above for this query. `visual_custom` should call `exercise_custom`."],"id":"f572d06d"},{"cell_type":"code","metadata":{"id":"5393e5c5"},"source":["def exercise_custom(df):\n","    # TODO\n","    pass\n","    \n","def visual_custom(df):\n","    # TODO\n","    pass"],"id":"5393e5c5","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ddecc786"},"source":["Submission\n","\n","1. Copy the exercises into `task1.py`.\n","2. Upload `task1.py` to Forage."],"id":"ddecc786"},{"cell_type":"markdown","metadata":{"id":"qpIxC3xgQpOo"},"source":["All done!\n","\n","Your work will be instrumental for our team's continued success."],"id":"qpIxC3xgQpOo"}]}